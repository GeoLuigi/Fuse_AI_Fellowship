{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f9a4ab",
   "metadata": {},
   "source": [
    "# KNN Algorithm\n",
    "\n",
    "<li>The KNearest Neighbor(KNN) algorithm is a type of supervised Learning used for classification and regression</li>\n",
    "<li>This algorithm considers the K closest neighbors to predict the class or continuous value for a new datapoint.</li>\n",
    "<li>KNN is a non parametric and an instance-based learning algorithm.</li>\n",
    "<li>Instead of learning the weights from training data, it memorizes the entire training instances to predict the output for new data.</li>\n",
    "<li>KNN has additional applications such as imputing missing values and resampling datasets.</li>\n",
    "<li>KNN algorithm is considered lazy learning because the learning process is postponed until prediction is requested on the new instance.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a32b31",
   "metadata": {},
   "source": [
    "## How KNN works?\n",
    "\n",
    "<li>The working of KNN is explained in the following steps:</li>\n",
    "<ol>\n",
    "    <li>Compute <b>similarity metric</b> for a new test case from the group of items.</li>\n",
    "    <li>Rank each listing by the similarity metric and select the top <b>k</b> listings with respect to the test case.</li>\n",
    "    <li>Calculate the average of top <b>k</b> items or mode of top n items based on the problem statement and return it as a prediction.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb4f5",
   "metadata": {},
   "source": [
    "## Parameters Of KNN Algorithm\n",
    "\n",
    "<li>There are two things we need to choose prior to applying KNN algorithm. They are:</li>\n",
    "<ol>\n",
    "    <li>Choice of similarity metric</li>\n",
    "    <li>Choosing appropriate value of k</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e6f41",
   "metadata": {},
   "source": [
    "## Similarity Metric\n",
    "\n",
    "<li>The KNN algorithm offers a variety of similarity metrics (distance metrics) to choose from. Some of them are:</li>\n",
    "<ol>\n",
    "    <li>Minkowski distance</li>\n",
    "    <li>Manhattan distance</li>\n",
    "    <li>Euclidean distance</li>\n",
    "    <li>Cosine similarity</li>\n",
    "    <li>Jaccard similarity</li>\n",
    "<ol>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38794910",
   "metadata": {},
   "source": [
    "### Minkowski Distance\n",
    "<li>Minkowski distance is a distance/ similarity measurement between two points in the normed vector space (N dimensional real space)</li>\n",
    "<li>It is a generalization of the Euclidean distance and the Manhattan distance.</li>\n",
    "<li>It is given by the formula:</li>\n",
    "\n",
    "![](images/minoski_distance.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5ec6a",
   "metadata": {},
   "source": [
    "### Manhattan Distance\n",
    "\n",
    "<li>Manhattan distance is a distance measure that is calculated by taking the sum of distances between the x and y coordinates.</li>\n",
    "<li>We can derive the formula to compute manhattan distance from minkowski distance formula.</li>\n",
    "<li>When we substitute the value for p=1, then we get the formula to compute manhattan distance.</li>\n",
    "<li>The formula to compute Manhattan distance is given by:</li>\n",
    "\n",
    "![](images/manhattan_dist.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f43b92",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "<li>Euclidean distance is a distance measure that is calculated by taking the square root of the sum of squared distances between the x and y coordinates.</li>\n",
    "<li>We can also derive the formula to compute euclidean distance from minkowski distance formula.</li>\n",
    "<li>When we substitute the value for p=2, then we get the formula to compute euclidean distance.</li>\n",
    "<li>The formula to compute Euclidean distance is given by:</li>\n",
    "\n",
    "![](images/euclidean_dist.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe01ce",
   "metadata": {},
   "source": [
    "### How To Choose Appropriate Value Of K\n",
    "\n",
    "<li>K is a crucial parameter in the KNN algorithm.Some suggestions for choosing K Value are:</li>\n",
    "<li>K value should be odd while considering binary(two-class) classification.</li>\n",
    "<li>There are no pre-defined statistical methods to find the appropriate value of K.</li>\n",
    "<li>Initialize a random K value and start computing.</li>\n",
    "<li>Choosing a small value of K leads to unstable decision boundaries.</li>\n",
    "<li>The optimal K value usually found is the square root of N, where N is the total number of samples.</li>\n",
    "<li>The substantial K value is better for classification as it leads to smoothening the decision boundaries.</li>\n",
    "<li>Domain knowledge can be very useful in choosing the K value.</li>\n",
    "<li>Derive a plot between error and K denoting values in a defined range. Then choose the K value as having a minimum error.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82d61d",
   "metadata": {},
   "source": [
    "### KNN For Classification\n",
    "\n",
    "<li>Suppose, we have a binary classification problems with two class; <b>Class A(red star)</b> and <b>Class B(green triangle)</b>.</li>\n",
    "<li>Let us suppose, we wanted to classify a new data point which is represented as <b>'?'</b> in the figure.</li>\n",
    "\n",
    "\n",
    "![](images/knn_classifier1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e24a01",
   "metadata": {},
   "source": [
    "![](images/knn_classifier2.png)\n",
    "\n",
    "<li>Then we will compute the distance from the new data point to all possible data points we have in our training set.</li>\n",
    "<li>We can compute any distance metrics; euclidean or manhattan distance and then rank the similarity based on their distance metrics.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7176c",
   "metadata": {},
   "source": [
    "![](images/knn_classifier3.png)\n",
    "\n",
    "<li>Once they are ranked, we will choose any value of <b>'k'</b>.</li>\n",
    "<li>Here, <b>k</b> denotes the number of nearest neigbours we are going to look for inorder to predict the new test data.</li>\n",
    "<li>If <b>k=3</b> then, we will look into the 3 nearest neighbors with the smallest distance to the test data.</li>\n",
    "<li>Then we will assign the newly test data with a class which occurs most often among the nearest neighbors.</li>\n",
    "<li>In the figure, out of 3 nearest neighbors, two of them belong to 'Class B' so we assign the newly test data with 'Class B'.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3b8db",
   "metadata": {},
   "source": [
    "![](images/knn_classifier4.png)\n",
    "\n",
    "<li>But when k=7, we will look for 7 nearest neighbors inorder to classify the new test data.</li>\n",
    "<li>In the figure, out of 4 nearest neighbors, 4 of them belong to 'Class A' and 3 of them belong to 'Class B'.</li>\n",
    "<li>Based on majority vote counting, we assign the new test data with 'Class A'.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edea82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff0690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046df0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99aa0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae19b605",
   "metadata": {},
   "source": [
    "### KNN For Regression\n",
    "\n",
    "<li>Incase of regression, the process is same untill the prediction step.</li>\n",
    "<li>Like classification, we will first compute distance similarity metric for the new test data against all training data.</li>\n",
    "<li>Then, we will rank all these distance metrics and based on the value of k we will choose first k values with the lowest distance.</li>\n",
    "<li>Since our target value is continuous incase of regression so instead of predicting the class we need to predict a value.</li>\n",
    "<li>So, for regression, we will predict the average of the top k values and return it as a prediction.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a5dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
