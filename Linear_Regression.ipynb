{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ea5ac4",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "<li>Linear regression is a statistical practice of calculating a straight line that specifies a mathematical relationship between two variables.</li>\n",
    "<li>Linear regression analysis is used to predict the value of a variable based on the value of another variable.</li>\n",
    "<li>The variable you want to predict is called the dependent variable.</li>\n",
    "<li>The variable you are using to predict the other variable's value is called the independent variable.</li>\n",
    "\n",
    "<ol>\n",
    "    <li>Simple Linear Regression</li>\n",
    "    <li>Multiple Linear Regression</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a51cc",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression\n",
    "<li>Simple linear regression is a regression model that estimates the relationship between one independent and one dependent variable using a straight line.</li>\n",
    "<li>Both variables should be quantitative.</li>\n",
    "\n",
    "<li>The following equation is the general form of the simple linear regression model.</li>\n",
    "<code>\n",
    "    ^\n",
    "    y =B0 + B1x1 \n",
    "</code>\n",
    "Where    \n",
    "^\n",
    "y represents the predicted value, \n",
    "x1 represents the feature column we choose to use in our model.\n",
    "<li>These values are independent of the dataset.</li>\n",
    "<li>On the other hand, B0 and B1 represent the parameter values that are specific to the dataset.</li>\n",
    "<li>The goal of simple linear regression is to find the optimal B0 and B1 values that best describe the relationship between the feature and the target column.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363f6dd",
   "metadata": {},
   "source": [
    "<li>The following diagram shows different simple linear regression models depending on the data:</li>\n",
    "\n",
    "![](images/regression_figure.png)\n",
    "\n",
    "<li>The first step is to select the feature x1, we want to use in our model.</li>\n",
    "<li>Once we select this feature, we can use scikit-learn to determine the optimal parameter values B0 and B1 based on the training data.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a420dd",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "<li>A multiple linear regression model allows us to capture the relationship between multiple feature columns and the target column.</li>\n",
    "<li>Here's what the formula looks like:\n",
    "<code>\n",
    "^\n",
    "y = B0 + B1x1 + B2x2 + ... + Bnxn\n",
    "</code>\n",
    "      ^\n",
    "<li>Where y represents the predicted value</li>\n",
    "<li>B0, B1, B2,..., Bn represents n parameter values that are specific to the dataset.</li>\n",
    "<li>The goal here is to find out the optimal values of B0, B1, B2 such that these features best represents the relationship between the data.</li>\n",
    "\n",
    "![](images/multiple_linear_regression.png)\n",
    "\n",
    "<li>The parameters values can be estimated using the following eqns:</li>\n",
    "\n",
    "![](images/mle_eqn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036892a",
   "metadata": {},
   "source": [
    "## Cost/Loss Function For Linear Regression\n",
    "\n",
    "<li>Cost function measures the performance of a machine learning model for a data set.</li>\n",
    "<li>Cost function quantifies the error between predicted and expected values and presents that error in the form of a single real number.</li>\n",
    "<li>Depending on the problem, cost function can be formed in many different ways.</li>\n",
    "<li>The purpose of cost function is to be either minimized or maximized.</li>\n",
    "<li>For algorithms relying on gradient descent to optimize model parameters, every function has to be differentiable.</li>\n",
    "\n",
    "![](images/cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e5d12",
   "metadata": {},
   "source": [
    "### Optimization (Using Gradient Descent)\n",
    "<li>Gradient descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function.</li>\n",
    "\n",
    "![](images/gradient_descent.jpg)\n",
    "\n",
    "\n",
    "#### Steps For Finding Gradient Descent\n",
    "\n",
    "![](images/gradient_descent_steps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257fd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93d2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c70fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04ccfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f268e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae05efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ace005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a930fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca4a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b492e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28976379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512deb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f10fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22c6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6faa4049",
   "metadata": {},
   "source": [
    "## Assumptions For Linear Regression\n",
    "<ol>\n",
    "<li><b>Linearity:</b> The relationship between the dependent variable and the independent variable(s) is linear.</li>\n",
    "<li><b>Independence:</b> The observations are independent of each other.</li>\n",
    "<li><b>Homoscedasticity:</b> The variance of the errors is constant across all levels of the independent variable(s).</li>\n",
    "<li><b>Normality:</b> The errors follow a normal distribution.</li>\n",
    "<li><b>No multicollinearity:</b> The independent variables are not highly correlated with each other.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa9a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698289d6",
   "metadata": {},
   "source": [
    "### 1. Linearity\n",
    "<li>Linearity means that there should be a linear relationship between the independent variable(s) and the dependent variable.</li>\n",
    "<li>In other words, the change in the dependent variable should be proportional to the change in the independent variable(s), with a constant slope and intercept.</li>\n",
    "\n",
    "For example, let's say you want to use linear regression to model the relationship between a person's height and their weight. If the relationship between height and weight is not linear, this would violate the assumption of linearity. In this case, the model may not be able to accurately capture the complex and nonlinear effects of height on weight, and may yield biased and inefficient estimates of the regression coefficients.\n",
    "\n",
    "Another example would be if you were studying the relationship between a company's sales revenue and its advertising budget. If the relationship between sales revenue and advertising budget is not linear, this would violate the assumption of linearity. In this case, the model may not be able to capture the diminishing or increasing returns to scale of the advertising budget on sales revenue, and may yield unreliable and inaccurate predictions of the sales revenue for different levels of advertising budget.\n",
    "\n",
    "<li>Violation of the linearity assumption can lead to biased and inefficient estimates of the regression coefficients, and can affect the validity of the model.</li> \n",
    "<li>Therefore, it is important to check for linearity when using linear regression.</li>\n",
    "<li>For example, by plotting the dependent variable against each independent variable and examining the scatter plot or trend line.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816b343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7b3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29689fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c83e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4392de1",
   "metadata": {},
   "source": [
    "### 2.Independence: \n",
    "<li>Independence is one of the assumptions of linear regression, which means that the observations should be independent of each other. </li>\n",
    "<li>This means that the value of the dependent variable for one observation should not be related to the value of the dependent variable for any other observation.</li>\n",
    "\n",
    "For example, let's say you want to use linear regression to model the relationship between a person's weight and their height. If you collect data from a group of identical twins, the weight and height of one twin would be highly correlated with the weight and height of their sibling, violating the assumption of independence. In this case, you would need to collect data from non-related individuals to ensure independence.\n",
    "\n",
    "Another example would be if you were studying the impact of a new medication on blood pressure. If you measured the blood pressure of the same person before and after taking the medication, the observations would not be independent because the values of blood pressure before and after the medication are related to each other for that person. In this case, you would need to collect data from different people who have a similar health condition and administer the medication to some of them, while the rest receive a placebo.\n",
    "\n",
    "<li>If the Durbin-Watson test statistic is close to 2 (e.g., between 1.5 and 2.5), this suggests that the residuals are independent.</li>\n",
    "<li>If the test statistic is significantly less than 2 or significantly greater than 2, this suggests the presence of positive or negative autocorrelation, respectively.</li> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5350fcc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13397c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d49171af",
   "metadata": {},
   "source": [
    "### 3. Homoscedasticity:\n",
    "<li>It is one of the assumptions of linear regression, which means that the variance of the errors is constant across all levels of the independent variable(s).</li> \n",
    "<li>In other words, the spread of the residuals should be similar across the range of the independent variable(s).</li>\n",
    "\n",
    "For example, let's say you want to use linear regression to model the relationship between a student's study time and their exam scores. If the variance of the errors increases or decreases as the study time increases, this would violate the assumption of homoscedasticity. In this case, the model may overemphasize the effect of the study time on the exam scores for some values of study time, while underemphasizing it for others.\n",
    "\n",
    "Another example would be if you were studying the relationship between a car's speed and its fuel efficiency. If the variance of the errors increases or decreases as the speed increases, this would violate the assumption of homoscedasticity. In this case, the model may overemphasize the effect of the speed on fuel efficiency for some speeds, while underemphasizing it for others.\n",
    "\n",
    "Violation of the homoscedasticity assumption can lead to biased and inefficient estimates of the regression coefficients, and can affect the validity of the statistical inferences and predictions based on the model. Therefore, it is important to check for homoscedasticity when using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff8b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6e406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425d942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a72e7a",
   "metadata": {},
   "source": [
    "### 4. Normality:\n",
    "<li>Normality is one of the assumptions of linear regression, which means that the errors (residuals) should follow a normal distribution.</li>\n",
    "<li>In other words, the distribution of the residuals should be symmetrical and bell-shaped around zero.</li>\n",
    "\n",
    "For example, let's say you want to use linear regression to model the relationship between a person's age and their cholesterol level. If the distribution of the residuals is skewed or has outliers, this would violate the assumption of normality. In this case, the model may be overestimating or underestimating the effect of age on cholesterol level, depending on the direction and magnitude of the skewness or outliers.\n",
    "\n",
    "Another example would be if you were studying the relationship between a company's advertising budget and its sales revenue. If the distribution of the residuals is not normal, this would violate the assumption of normality. In this case, the model may not accurately capture the nonlinearities and interactions between the variables, and the estimated confidence intervals and p-values may be inaccurate.\n",
    "\n",
    "<li>Violation of the normality assumption can lead to biased and inefficient estimates of the regression coefficients.</li> <li>It can also affect the validity of the statistical inferences and predictions based on the model.</li>\n",
    "<li>Therefore, it is important to check for normality when using linear regression.</li>\n",
    "<li>For example, by examining the histogram, Q-Q plot, or normal probability plot of the residuals, we can check normality.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58b176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a865d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc31c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b72495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb229458",
   "metadata": {},
   "source": [
    "### 5. No multicollinearity\n",
    "\n",
    "<li>No multicollinearity is one of the assumptions of linear regression, which means that the independent variables should not be highly correlated with each other.</li>\n",
    "<li>In other words, there should be no perfect or near-perfect linear relationship between any two or more independent variables.</li>\n",
    "\n",
    "For example, let's say you want to use linear regression to model the relationship between a student's exam scores and their study time, their attendance rate, and their participation in a review session. If study time and attendance rate are highly correlated with each other, this would violate the assumption of no multicollinearity. In this case, the model may not be able to distinguish between the effects of study time and attendance rate on the exam scores, and the estimated regression coefficients and their standard errors may be unstable or even impossible to calculate.\n",
    "\n",
    "Another example would be if you were studying the relationship between a car's fuel efficiency and its engine size, weight, and horsepower. If engine size and horsepower are highly correlated with each other, this would violate the assumption of no multicollinearity. In this case, the model may not be able to separate the effects of engine size and horsepower on fuel efficiency, and the estimated regression coefficients and their standard errors may be unreliable or even misleading.\n",
    "\n",
    "Violation of the no multicollinearity assumption can lead to unstable and inaccurate estimates of the regression coefficients, and can affect the interpretation and prediction of the model. Therefore, it is important to check for multicollinearity when using linear regression.\n",
    "\n",
    "<li>If the VIF values are greater than 5 or 10, this indicates problematic levels of multicollinearity, and you may need to consider removing one of the correlated features, transforming the data, or using a different model that is robust to multicollinearity.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57c9ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c505c95",
   "metadata": {},
   "source": [
    "### Performance Metrics In Linear Regression\n",
    "\n",
    "<li>Mean Absolute Error</li>\n",
    "<li>Mean Squared Error</li>\n",
    "<li>Root Mean Squared Error</li>\n",
    "<li>R2</li>\n",
    "<li>Adjuster R2</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import scipy.stats as stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from statsmodels.stats.stattools import durbin_watson\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
