{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ea5ac4",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "<li>Linear regression is a statistical practice of calculating a straight line that specifies a mathematical relationship between two variables.</li>\n",
    "<li>Linear regression analysis is used to predict the value of a variable based on the value of another variable.</li>\n",
    "<li>The variable you want to predict is called the dependent variable.</li>\n",
    "<li>The variable you are using to predict the other variable's value is called the independent variable.</li>\n",
    "\n",
    "<ol>\n",
    "    <li>Simple Linear Regression</li>\n",
    "    <li>Multiple Linear Regression</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a51cc",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression\n",
    "<li>Simple linear regression is a regression model that estimates the relationship between one independent and one dependent variable using a straight line.</li>\n",
    "<li>Both variables should be quantitative.</li>\n",
    "\n",
    "<li>The following equation is the general form of the simple linear regression model.</li>\n",
    "<code>\n",
    "    ^\n",
    "    y =B0 + B1x1 \n",
    "</code>\n",
    "Where    \n",
    "^\n",
    "y represents the predicted value, \n",
    "x1 represents the feature column we choose to use in our model.\n",
    "<li>These values are independent of the dataset.</li>\n",
    "<li>On the other hand, B0 and B1 represent the parameter values that are specific to the dataset.</li>\n",
    "<li>The goal of simple linear regression is to find the optimal B0 and B1 values that best describe the relationship between the feature and the target column.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363f6dd",
   "metadata": {},
   "source": [
    "<li>The following diagram shows different simple linear regression models depending on the data:</li>\n",
    "\n",
    "![](images/regression_figure.png)\n",
    "\n",
    "<li>The first step is to select the feature x1, we want to use in our model.</li>\n",
    "<li>Once we select this feature, we can use scikit-learn to determine the optimal parameter values B0 and B1 based on the training data.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ed3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff9039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3ae9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5ab10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ed163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b424b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3605d5c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d41159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9adf6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58bd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6d870bf",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d9a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95359581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad92955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c822b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5bd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df7a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f84f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e48932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27319885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba2da846",
   "metadata": {},
   "source": [
    "## Cost/Loss Function For Linear Regression\n",
    "\n",
    "<li>Cost function measures the performance of a machine learning model for a data set.</li>\n",
    "<li>Cost function quantifies the error between predicted and expected values and presents that error in the form of a single real number.</li>\n",
    "<li>Depending on the problem, cost function can be formed in many different ways.</li>\n",
    "<li>The purpose of cost function is to be either minimized or maximized.</li>\n",
    "<li>For algorithms relying on gradient descent to optimize model parameters, every function has to be differentiable.</li>\n",
    "\n",
    "![](images/cost_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b1b27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fab87ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjr2(actual, predicted,n, d):\n",
    "    \"\"\" R2 Score \"\"\"\n",
    "    return 1-(1-r2_score(actual,predicted))* (n-1)/(n-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f123ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1851d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f524f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2746e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31f6080c",
   "metadata": {},
   "source": [
    "### Optimization (Using Gradient Descent)\n",
    "<li>Gradient descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function.</li>\n",
    "\n",
    "![](images/gradient_descent.jpg)\n",
    "\n",
    "\n",
    "#### Steps For Finding Gradient Descent\n",
    "\n",
    "![](images/gradient_descent_steps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3944be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a420dd",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "<li>A multiple linear regression model allows us to capture the relationship between multiple feature columns and the target column.</li>\n",
    "<li>Here's what the formula looks like:\n",
    "<code>\n",
    "^\n",
    "y = B0 + B1x1 + B2x2 + ... + Bnxn\n",
    "</code>\n",
    "      ^\n",
    "<li>Where y represents the predicted value</li>\n",
    "<li>B0, B1, B2,..., Bn represents n parameter values that are specific to the dataset.</li>\n",
    "<li>The goal here is to find out the optimal values of B0, B1, B2 such that these features best represents the relationship between the data.</li>\n",
    "\n",
    "![](images/multiple_linear_regression.png)\n",
    "\n",
    "<li>The parameters values can be estimated using the following eqns:</li>\n",
    "\n",
    "![](images/mle_eqn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847bd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3e96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0fb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff93eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113fde56",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be973381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d8c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee8484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e5395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f1449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa619d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1196fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c7610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8af18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b66e28b",
   "metadata": {},
   "source": [
    "### Performance Metrics In Linear Regression\n",
    "<li>To evaluate the performance or quality of the model, different metrics are used, and these metrics are known as performance metrics or evaluation metrics.</li>\n",
    "<li>Some of the performance metrics used in linear regression are:</li>\n",
    "<ol>\n",
    "    <b><li>Mean Absolute Error</li></b>\n",
    "    <b><li>Mean Squared Error</li></b>\n",
    "    <b><li>Root Mean Squared Error</li></b>\n",
    "    <b><li>R²</li></b>\n",
    "    <b><li>Adjuster R²</li></b>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a611986",
   "metadata": {},
   "source": [
    "### Mean Absolute Error\n",
    "<li>Absolute Error is the amount of error in your measurements. It is the difference between the measured value and “true” value.</li>\n",
    "<li>For example, if a scale states 90 pounds but you know your true weight is 89 pounds, then the scale has an absolute error of 90 lbs – 89 lbs = 1 lbs.</li>\n",
    "<li>In machine learning, mean absolute error is the average difference between the actual  values and the predicted values of the model.</li>\n",
    "<li>MAE measures the average magnitude of the errors in a set of predictions, without considering their direction.</li>\n",
    "<li>The formula to calculate MAE is given by:</li>\n",
    "\n",
    "![](images/mae.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060abc5",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "<li>In statistics, the mean squared error (MSE) of an estimator measures the average of the squares of the errors.</li>\n",
    "<li>The mean squared error (MSE) tells you how close a regression line is to a set of points.</li>\n",
    "<li>It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.</li>\n",
    "<li>The squaring is necessary to remove any negative signs. It also gives more weight to larger differences.</li>\n",
    "<li>It’s called the mean squared error as you’re finding the average of a set of errors.</li>\n",
    "<li>The lower the MSE, the better the forecast.</li>\n",
    "<li>In machine learning, mean squared error is the average difference between the squares of actual values and the predicted values.</li>\n",
    "<li>The formula to calculate mean squared error is given by:</li>\n",
    "\n",
    "![](images/mse.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de8833",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "<li>RMSE is a quadratic scoring rule that also measures the average magnitude of the error.</li>\n",
    "<li>It’s the square root of the average of squared differences between prediction and actual observation.</li>\n",
    "<li>The formula to calculate RMSE is given by:</li>\n",
    "\n",
    "![](images/rmse.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72138671",
   "metadata": {},
   "source": [
    "### R²\n",
    "<li>R-Squared determines the proportion of variance in the dependent variable that can be explained by the independent variable.</li>\n",
    "<li>In other words, r-squared shows how well the data fit the regression model (the goodness of fit).</li>\n",
    "<li>R-squared measures the strength of the relationship between your model and the dependent variable on a scale of 0 – 1.</li>\n",
    "</li>Usually, the larger the R2, the better the regression model fits your observations.</li>\n",
    "<li>The formula to calculate R2 is given by:</li>\n",
    "\n",
    "![](images/r2_score.png)\n",
    "\n",
    "<li>But sometimes, small R-squared values are not always a problem, and high R-squared values are not necessarily good.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af01efc",
   "metadata": {},
   "source": [
    "![](images/r2_range.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a03e6",
   "metadata": {},
   "source": [
    "![](images/r2_problems.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192dc8e",
   "metadata": {},
   "source": [
    "### Adjusted R2\n",
    "<li>Adjusted R2 is a corrected goodness-of-fit (model accuracy) measure for linear models.</li>\n",
    "<li>Adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model.</li>\n",
    "<li>The adjusted R-squared increases when the new term improves the model more than would be expected by chance.</li>\n",
    "<li>It decreases when a predictor improves the model by less than expected.</li>\n",
    "\n",
    "![](images/r2_adjusted.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805af799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd104bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5304c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d9228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003ff24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a29ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5df1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a836c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74169903",
   "metadata": {},
   "source": [
    "### Bias Variance TradeOffs In Machine Learning\n",
    "\n",
    "![](images/bias_variance_tradeoff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998824a8",
   "metadata": {},
   "source": [
    "### Regularization In Regression\n",
    "\n",
    "<li>During the Machine Learning model building, the Regularization Techniques is an unavoidable and important step to improve the model.</li>\n",
    "<li>This is also called the Shrinkage method in which we use to add the penalty term to control the complex model to avoid overfitting by reducing the variance.</li>\n",
    "<li>In regression, we can came across overfitted model where the best fit line works best for the training dataset but fails for testing datasets.</li>\n",
    "<li>To prevent from such overfitting problem, we have two different methods in regression. They are :</li>\n",
    "<ol>\n",
    "    <b><li>Lasso Regression</li></b>\n",
    "    <b><li>Ridge Regression</li></b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df263e87",
   "metadata": {},
   "source": [
    "### 1. Lasso Regression\n",
    "\n",
    "<li>Lasso Regression is also called as L1 regularization technique.</li>\n",
    "<li>We can use lasso regression for feature selection as well because the beta coefficients can be shrinked down to 0 incase of lasso regression.</li>\n",
    "<li>In lasso regression, we add the absolute values of the regression coefficients as a penalty term to reduce overfitting.</li>\n",
    "<li>The formula to calculate lasso regression is given by:</li>\n",
    "\n",
    "\n",
    "![](images/lasso_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4f4f6",
   "metadata": {},
   "source": [
    "![](images/lasso.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fcbf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303e831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4cd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4b5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb870a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186195d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc374e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60221998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61355984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35708f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b092161e",
   "metadata": {},
   "source": [
    "### 2. Ridge Regession\n",
    "\n",
    "<li>Ridge Regression is also called as L2 regularization technique.</li>\n",
    "<li>We can not use ridge regression for feature selection as well because the beta coefficients can only be shrinked down to lower values but not 0.</li>\n",
    "<li>In ridge regression, we add the squared values of the regression coefficients as a penalty term to reduce overfitting.</li>\n",
    "<li>The formula to calculate ridge regression is given by:</li>\n",
    "\n",
    "![](images/ridge_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6b90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b323f198",
   "metadata": {},
   "source": [
    "![](images/ridge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282e376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5e867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76953eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4f45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8139bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf7b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487843e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778acac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99a340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d2e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04363eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf960d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
